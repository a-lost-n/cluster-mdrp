{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:34:02.708848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 15:34:05.957201: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 6. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "agent = DDQNAgent(restaurant_array=[2,6,2], grid_size=100, randseed=25)\n",
    "# agent = DDQNAgent(restaurant_array=[2,6,2], grid_size=100, randseed=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.map.display_map_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.train_by_timestamp(episodes=200, batch_size=16, epsilon=1, epsilon_decay=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0]] 0.0002467632293701172\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m episodios_terminados \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m agent\u001b[39m.\u001b[39mtrain(episodes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mepisodios_terminados, epsilon_decay\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m)\n",
      "File \u001b[0;32m~/Tesis/cluster-mdrp/src/ddqn.py:188\u001b[0m, in \u001b[0;36mDDQNAgent.train\u001b[0;34m(self, episodes, batch_size, epsilon, epsilon_decay)\u001b[0m\n\u001b[1;32m    186\u001b[0m     run_rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremember(experiences)\n\u001b[0;32m--> 188\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay(batch_size)\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m count \u001b[39m%\u001b[39m \u001b[39m24\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    190\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mreshape(state, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_size,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mtolist(), time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstart_time)\n",
      "File \u001b[0;32m~/Tesis/cluster-mdrp/src/ddqn.py:70\u001b[0m, in \u001b[0;36mDDQNAgent.replay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m minibatch \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory, batch_size)\n\u001b[1;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m state, action, reward, next_state, done \u001b[39min\u001b[39;00m minibatch:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(state, action, reward, next_state, done)\n",
      "File \u001b[0;32m~/Tesis/cluster-mdrp/src/ddqn.py:63\u001b[0m, in \u001b[0;36mDDQNAgent.fit\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     61\u001b[0m     Q_future \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mamax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model\u001b[39m.\u001b[39mpredict(next_state, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     62\u001b[0m     target[\u001b[39m0\u001b[39m][action] \u001b[39m=\u001b[39m reward \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m Q_future\n\u001b[0;32m---> 63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(state, target, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/engine/training.py:1625\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m (\n\u001b[1;32m   1616\u001b[0m         tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1617\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1618\u001b[0m         )\n\u001b[1;32m   1619\u001b[0m     )\n\u001b[1;32m   1621\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   1623\u001b[0m ):\n\u001b[1;32m   1624\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1625\u001b[0m     data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1626\u001b[0m         x\u001b[39m=\u001b[39mx,\n\u001b[1;32m   1627\u001b[0m         y\u001b[39m=\u001b[39my,\n\u001b[1;32m   1628\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1629\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1630\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39msteps_per_epoch,\n\u001b[1;32m   1631\u001b[0m         initial_epoch\u001b[39m=\u001b[39minitial_epoch,\n\u001b[1;32m   1632\u001b[0m         epochs\u001b[39m=\u001b[39mepochs,\n\u001b[1;32m   1633\u001b[0m         shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[1;32m   1634\u001b[0m         class_weight\u001b[39m=\u001b[39mclass_weight,\n\u001b[1;32m   1635\u001b[0m         max_queue_size\u001b[39m=\u001b[39mmax_queue_size,\n\u001b[1;32m   1636\u001b[0m         workers\u001b[39m=\u001b[39mworkers,\n\u001b[1;32m   1637\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39muse_multiprocessing,\n\u001b[1;32m   1638\u001b[0m         model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1639\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1640\u001b[0m     )\n\u001b[1;32m   1642\u001b[0m     \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1261\u001b[0m     x,\n\u001b[1;32m   1262\u001b[0m     y,\n\u001b[1;32m   1263\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1264\u001b[0m     steps\u001b[39m=\u001b[39msteps_per_epoch,\n\u001b[1;32m   1265\u001b[0m     epochs\u001b[39m=\u001b[39mepochs \u001b[39m-\u001b[39m initial_epoch,\n\u001b[1;32m   1266\u001b[0m     sample_weights\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m   1267\u001b[0m     shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[1;32m   1268\u001b[0m     max_queue_size\u001b[39m=\u001b[39mmax_queue_size,\n\u001b[1;32m   1269\u001b[0m     workers\u001b[39m=\u001b[39mworkers,\n\u001b[1;32m   1270\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39muse_multiprocessing,\n\u001b[1;32m   1271\u001b[0m     distribution_strategy\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy(),\n\u001b[1;32m   1272\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1275\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/engine/data_adapter.py:348\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    346\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 348\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    352\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mshuffle_batch\u001b[39m(\u001b[39m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/keras/engine/data_adapter.py:389\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    385\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    386\u001b[0m         \u001b[39mlambda\u001b[39;00m d: tf\u001b[39m.\u001b[39mgather(d, i, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), data\n\u001b[1;32m    387\u001b[0m     )\n\u001b[0;32m--> 389\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(grab_batch, num_parallel_calls\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[1;32m    391\u001b[0m \u001b[39m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39m# (unnecessary) input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    393\u001b[0m options \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39m_map_v2(\n\u001b[1;32m   2241\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2242\u001b[0m     map_func,\n\u001b[1;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[1;32m   2245\u001b[0m     name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[1;32m     43\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39mnum_parallel_calls,\n\u001b[1;32m     44\u001b[0m       deterministic\u001b[39m=\u001b[39mdeterministic,\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39mStructuredFunctionWrapper(\n\u001b[1;32m    149\u001b[0m     map_func,\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformation_name(),\n\u001b[1;32m    151\u001b[0m     dataset\u001b[39m=\u001b[39minput_dataset,\n\u001b[1;32m    152\u001b[0m     use_legacy_function\u001b[39m=\u001b[39muse_legacy_function)\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[1;32m    233\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_concrete_function(\n\u001b[1;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:299\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m--> 299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m    300\u001b[0m     func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    301\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name,\n\u001b[1;32m    302\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function,\n\u001b[1;32m    303\u001b[0m         args,\n\u001b[1;32m    304\u001b[0m         kwargs,\n\u001b[1;32m    305\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39mfunc_graph,\n\u001b[1;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph,\n\u001b[1;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autograph_options,\n\u001b[1;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39marg_names,\n\u001b[1;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_capture_by_value,\n\u001b[1;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1362\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[0;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[1;32m   1356\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_garbage_collector \u001b[39m=\u001b[39m ConcreteFunctionGarbageCollector(func_graph)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Pairs of forward and backward functions used for computing gradients.\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[39m# These each get a reference to the FuncGraph deleter since they use the\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m \u001b[39m# FuncGraph directly.\u001b[39;00m\n\u001b[0;32m-> 1362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_delayed_rewrite_functions \u001b[39m=\u001b[39m _DelayedRewriteGradientFunctions(\n\u001b[1;32m   1363\u001b[0m     func_graph, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_garbage_collector)\n\u001b[1;32m   1364\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_order_tape_functions \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1365\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_higher_order_tape_functions \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:466\u001b[0m, in \u001b[0;36m_DelayedRewriteGradientFunctions.__init__\u001b[0;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_function_pairs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    465\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph \u001b[39m=\u001b[39m func_graph\n\u001b[0;32m--> 466\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function \u001b[39m=\u001b[39m _EagerDefinedFunction(\n\u001b[1;32m    467\u001b[0m     _inference_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mname), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph,\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39moutputs, attrs)\n\u001b[1;32m    469\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_attrs \u001b[39m=\u001b[39m attrs\n\u001b[1;32m    470\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tesis/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:226\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.__init__\u001b[0;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m   output_names \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 226\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    227\u001b[0m   fn \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GraphToFunction_wrapper(\n\u001b[1;32m    228\u001b[0m       c_graph,\n\u001b[1;32m    229\u001b[0m       compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    238\u001b[0m       compat\u001b[39m.\u001b[39mas_str(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_func \u001b[39m=\u001b[39m c_api_util\u001b[39m.\u001b[39mScopedTFFunction(fn, name)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodios_terminados = 0\n",
    "agent.train(episodes=1, batch_size=16, epsilon=0.99**episodios_terminados, epsilon_decay=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.train(episodes=5, batch_size=16, epsilon=0.97, epsilon_decay=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test_state([0,1,0,0,1,0,0,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34553206 -0.23699665  0.16721748  0.55883265 -0.31494483  0.0697531\n",
      "  -0.01936247  0.5757936  -0.30210802]]\n",
      "[[ 0.44901508 -0.2963739   0.25613713  0.5909995  -0.4720938   0.03931555\n",
      "  -0.2099417   0.64508206 -0.49152213]]\n"
     ]
    }
   ],
   "source": [
    "print(agent.model.predict([[0,1,0,0,1,0,0,3,0]], verbose=0))\n",
    "print(agent.model.predict([[0,1,0,0,1,0,1,3,0]], verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eb9f84fefceafe1a3c435496fbe13a2b44a56f2830201ddc530946f22d6bea4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
